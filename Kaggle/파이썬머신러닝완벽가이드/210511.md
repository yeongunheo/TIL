# Exercise: New York City Taxi Fare Prediction
## Python notebook using data from New York City Taxi Fare Prediction

### 오늘 배운 것
1. train_test_split() 를 통해 학습데이터와 테스트 데이터를 나눌 수 있다.
2. 학습 데이터와 테스트 데이터를 나누는 것의 문제점
   => 과적합에 취약하다.
   과적합이란 모델이 학습 데이터에만 과도하게 최적화되어 실제 예측시 성능이 과도하게 떨어지는 것을 말한다.
3. 해결책: 교차검증

### 코드
```python
from sklearn.datasets import load_iris
from sklearn.tree import DecisionTreeClassifier
from sklearn.model_selection import train_test_split

import pandas as pd

#------------------------------------------------------------------------------------
# 02. 첫번째 머신러닝 만들어 보기 - 붓꽃 품종 예측하기
#------------------------------------------------------------------------------------
# 붓꽃 데이터 세트를 로딩합니다.
iris = load_iris()

# iris.data는 Iris 데이터 세트에서 피처(feature)만으로 된 데이터를 numpy로 가지고 있습니다.
iris_data = iris.data

# iris.target은 붓꽃 데이터 세트에서 레이블(결정 값) 데이터를 numpy로 가지고 있습니다.
iris_label = iris.target
print('iris target값:', iris_label)
print('iris target명:', iris.target_names)

# 붓꽃 데이터 세트를 자세히 보기위해 DataFrame으로 변환합니다.
iris_df = pd.DataFrame(data=iris_data, columns=iris.feature_names)
iris_df['label'] = iris.target
iris_df.head(3)

# 학습데이터와 테스트데이터 분리
X_train, X_test, y_train, y_test = train_test_split(iris_data, iris_label, test_size=0.2, random_state=11)

# DecisionTreeClassifier 객체 생성
dt_clf = DecisionTreeClassifier(random_state=11)
# 학습 수행
dt_clf.fit(X_train, y_train)

# 학습이 완료된 DecisionTreeClassifier 객체에서 테스트 데이터 세트로 예측 수행.
pred = dt_clf.predict(X_test)

# 머신러닝 모델 정확도 평가
from sklearn.metrics import accuracy_score
print('예측 정확도: {0:.4f}'.format(accuracy_score(y_test, pred)))

#------------------------------------------------------------------------------------
# 03. 사이킷런의 기반 프레임워크 익히기
#------------------------------------------------------------------------------------

from sklearn.datasets import load_iris

iris_data = load_iris()
print(type(iris_data)) # 사이킷런의 Bunch 클래스임을 알 수 있다.

keys = iris_data.keys()
print('붓꽃 데이터 세트의 키들:', keys)

print('\n feature_names 의 type:', type(iris_data.feature_names))
print(' feature_names 의 shape:', len(iris_data.feature_names))
print(iris_data.feature_names)

print('\n target_names 의 type:', type(iris_data.target_names))
print(' target_names 의 shape:', len(iris_data.target_names))
print(iris_data.target_names)

print('\n data 의 type:', type(iris_data.data))
print(' data 의 shape:', len(iris_data.data))
print(iris_data['data'])

print('\n target 의 type:', type(iris_data.target))
print(' data target shape:', len(iris_data.target.shape))
print(iris_data.target)

#------------------------------------------------------------------------------------
# 04. Model Selection 모듈 소개
#------------------------------------------------------------------------------------

# 학습데이터 세트로 학습과 예측을 동시에 할 시 예측정확도가 100%가 된다는 문제점이 생긴다.
from sklearn.datasets import load_iris
from sklearn.tree import DecisionTreeClassifier
from sklearn.metrics import accuracy_score

iris = load_iris()
dt_clf = DecisionTreeClassifier()
train_data = iris.data
train_label = iris.target
dt_clf.fit(train_data, train_label)

# 학습 데이터 세트로 예측 수행
pred = dt_clf.predict(train_data)
print('예측 정확도:', accuracy_score(train_label, pred))

# 학습/테스트 데이터 세트 분리 - train_test_split()
from sklearn.tree import DecisionTreeClassifier
from sklearn.metrics import accuracy_score
from sklearn.datasets import load_iris
from sklearn.model_selection import train_test_split

dt_clf = DecisionTreeClassifier()
iris_data = load_iris()

X_train, X_test, y_train, y_test = train_test_split(iris_data.data, iris_data.target, \
                                                    test_size=0.3, random_state=121)
                                                    
dt_clf.fit(X_train, y_train)
pred = dt_clf.predict(X_test)
print('예측 정확도: {0:.4f}'.format(accuracy_score(y_test, pred)))

```
